{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266298d-994d-47bb-b720-1ad02e94e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "##objective of the session\n",
    "# 1) tackle data types often found in real-world datasets (missing values, categorical variables),\n",
    "# 2) design pipelines to improve the quality of your machine learning code,\n",
    "# 3) use advanced techniques for model validation (cross-validation),\n",
    "# 4) build state-of-the-art models that are widely used to win Kaggle competitions (XGBoost), and\n",
    "# 5) avoid common and important data science mistakes (leakage).\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37ac0b57-824c-4374-9369-213f5be111c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing Prices Competition for Kaggle Learn Users\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read data\n",
    "X_full = pd.read_csv(r\"C:\\Users\\VI00592\\GitHub\\kaggle_learn\\Intermediate Machine Learning\\train.csv\")\n",
    "X_test_full = pd.read_csv(r\"C:\\Users\\VI00592\\GitHub\\kaggle_learn\\Intermediate Machine Learning\\test.csv\")\n",
    "\n",
    "#obtain target and predictors\n",
    "y = X_full.SalePrice\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()\n",
    "\n",
    "#derive validation set from Training set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e64e41f1-f03f-4c42-9adb-de1ce265728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "X_test_full.head()\n",
    "#print (X_test)\n",
    "\n",
    "print(X_test_full['Id'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bb92fcd-9210-4434-bb9f-0a45d614b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating five different random forest models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#define the model\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "482197cd-5b44-4020-8cd2-d1aebf67997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MAE: 24015\n",
      "Model 2 MAE: 23740\n",
      "Model 3 MAE: 23528\n",
      "Model 4 MAE: 23996\n",
      "Model 5 MAE: 23706\n"
     ]
    }
   ],
   "source": [
    "#MAE score to evaluate the efficency of different models\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#function to compare different models\n",
    "def score_model(model, X_t = X_train, X_v = X_valid, y_t = y_train, y_v = y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range (0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" %(i+1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b63c6d78-9450-4816-82e2-43318b40fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model is model_3\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fcddc96-92c5-4df3-b122-0a4d46bb314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the best model\n",
    "my_model.fit(X,y)\n",
    "\n",
    "#generate the test predictions\n",
    "preds_test = my_model.predict(X_test)\n",
    "\n",
    "#save the prediction in the format required\n",
    "output = pd.DataFrame({\"Id\" : X_test.index, \"Saleprice\" : preds_test})\n",
    "output.to_csv ('my_submission', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02786764-3479-4f7c-b79d-9d9f8f652ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
